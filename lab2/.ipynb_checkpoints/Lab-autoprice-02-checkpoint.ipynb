{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "894cfb81",
   "metadata": {},
   "source": [
    "# Data for autoprice   ( Normalization & mean )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0b56b1c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Class of k-Nearest Neigbor Classifier\n",
    "\n",
    "\n",
    "class kNN():\n",
    "    maxTrain = []\n",
    "    \n",
    "    def __init__(self, k = 3, exp = 2):\n",
    "    # constructor for kNN classifier \n",
    "    # k is the number of neighbor for local class estimation\n",
    "    # exp is the exponent for the Minkowski distance\n",
    "        self.k = k\n",
    "        self.exp = exp\n",
    "      \n",
    "    def fit(self, X_train, Y_train):\n",
    "    # training k-NN method\n",
    "    # X_train is the training data given with input attributes. n-th row correponds to n-th instance.\n",
    "    # Y_train is the output data (output vector): n-th element of Y_train is the output value for n-th instance in X_train.\n",
    "        self.X_train = X_train\n",
    "        self.Y_train = Y_train   \n",
    "         \n",
    "    def getDiscreteClassification(self, X_test):\n",
    "    # predict-class k-NN method\n",
    "    # X_test is the test data given with input attributes. Rows correpond to instances\n",
    "    # Method outputs prediction vector Y_pred_test:  n-th element of Y_pred_test is the prediction for n-th instance in X_test\n",
    "    \n",
    "        Y_pred_test = [] #prediction vector Y_pred_test for all the test instances in X_test is initialized to empty list []\n",
    "\n",
    "   \n",
    "    \n",
    "        for i in range(len(X_test)):   #iterate over all instances in X_test\n",
    "            test_instance = X_test.iloc[i] #i-th test instance \n",
    "            \n",
    "            distances = []  #list of distances of the i-th test_instance for all the train_instance s in X_train, initially empty.\n",
    "          \n",
    "            for j in range(len(self.X_train)):  #iterate over all instances in X_train\n",
    "                train_instance = self.X_train.iloc[j] #j-th training instance \n",
    "                distance = self.Minkowski_distance(test_instance, train_instance) #distance between i-th test instance and j-th training instance  \n",
    "                distances.append(distance) #add the distance to the list of distances of the i-th test_instance\n",
    "        \n",
    "            # Store distances in a dataframe. The dataframe has the index of Y_train in order to keep the correspondence with the classes of the training instances \n",
    "            df_dists = pd.DataFrame(data=distances, columns=['dist'], index = self.Y_train.index)\n",
    "        \n",
    "            # Sort distances, and only consider the k closest points in the new dataframe df_knn\n",
    "            df_nn = df_dists.sort_values(by=['dist'], axis=0)\n",
    "            df_knn =  df_nn[:self.k]\n",
    "            \n",
    "            # Note that the index df_knn.index of df_knn contains indices in Y_train of the k-closed training instances to \n",
    "            # the i-th test instance. Thus, the dataframe self.Y_train[df_knn.index] contains the classes of those k-closed \n",
    "            # training instances. Method value_counts() computes the counts (number of occurencies) for each class in \n",
    "            # self.Y_train[df_knn.index] in dataframe predictions. \n",
    "            predictions = self.Y_train[df_knn.index].value_counts()\n",
    "                 \n",
    "            # the first element of the index predictions.index contains the class with the highest count; i.e. the prediction y_pred_test.\n",
    "            y_pred_test = predictions.index[0]\n",
    "\n",
    "            # add the prediction y_pred_test to the prediction vector Y_pred_test for all the test instances in X_test\n",
    "            Y_pred_test.append(y_pred_test)\n",
    "        \n",
    "        return Y_pred_test\n",
    "\n",
    "    \n",
    "    def Minkowski_distance(self, x1, x2):\n",
    "    # computes the Minkowski distance of x1 and x2 for two labeled instances (x1,y1) and (x2,y2)\n",
    "    \n",
    "        # Set initial distance to 0\n",
    "        distance = 0\n",
    "    \n",
    "        # Calculate Minkowski distance using the exponent exp\n",
    "        for i in range(len(x1)):\n",
    "            distance = distance + abs(x1[i] - x2[i])**self.exp\n",
    "        \n",
    "        distance = distance**(1/self.exp)\n",
    "    \n",
    "        return distance\n",
    "    \n",
    "    \n",
    "    def normilize_maximum_absolute_scaling(self,df):   \n",
    "        # copy the dataframe\n",
    "        df_scaled = df.copy()\n",
    "        # apply maximum absolute scaling \n",
    "        for column in df_scaled.columns:  \n",
    "              df_scaled[column] = df_scaled[column]  / df_scaled[column].abs().max()\n",
    "           \n",
    "        return df_scaled\n",
    "    \n",
    "        \n",
    "    def getPrediction (self, X_test):\n",
    "        \n",
    "            # getting value type for Y\n",
    "        Y_type_list =  Y_train.tolist()\n",
    "        Y_type_no_dublicate = list(dict.fromkeys(Y_type_list))\n",
    "        \n",
    "        #creating new datafaram for Mean\n",
    "        df_mean = pd.DataFrame(index=Y_type_no_dublicate)\n",
    "        \n",
    "        Y_pred_test = [] #prediction vector Y_pred_test for all the test instances in X_test is initialized to empty list []\n",
    "        for i in range(len(X_test)):   #iterate over all instances in X_test\n",
    "            test_instance = X_test.iloc[i] #i-th test instance \n",
    "            \n",
    "            distances = []  #list of distances of the i-th test_instance for all the train_instance s in X_train, initially empty.\n",
    "          \n",
    "            for j in range(len(self.X_train)):  #iterate over all instances in X_train\n",
    "                train_instance = self.X_train.iloc[j] #j-th training instance \n",
    "                distance = self.Minkowski_distance(test_instance, train_instance) #distance between i-th test instance and j-th training instance  \n",
    "                distances.append(distance) #add the distance to the list of distances of the i-th test_instance\n",
    "        \n",
    "            df_dists = pd.DataFrame(data=distances, columns=['dist'], index = self.Y_train.index)\n",
    "#             print(df_dists)\n",
    "            df_nn = df_dists.sort_values(by=['dist'], axis=0)\n",
    "            df_knn =  df_nn[:self.k]\n",
    "            # clacultaing mean for each test data \n",
    "            mean = self.Y_train[dfknn.index].mean()\n",
    "            \n",
    "        \n",
    "            df_main['test'+str(i)] = mean\n",
    "                \n",
    "        \n",
    "        print(df_main)\n",
    "                \n",
    "        \n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e0ee495",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6637175e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
